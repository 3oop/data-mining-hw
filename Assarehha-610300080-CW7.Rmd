---
title: "Data Mining Class Work Chapter 7"
author: "Pooria Assarehha"
date: "2024-01-04"
output: pdf_document
---

Setting up the database

```{r}
Age = c(22, 33, 28, 51, 25, 39, 54, 55, 50, 66)
Marital = c("Single", "Married", "Other", "Other", "Single", "Single", "Single", "Married", "Married", "Married")
Income = c(46156.98, 24188.10, 28787.34, 23886.72, 47281.44, 33994.90, 28716.50, 49186.75, 46726.50, 36120.34)
Risk = c("Bad loss", "Bad loss", "Bad loss", "Bad loss", "Bad loss", "Good risk", "Good risk", "Good risk", "Good risk", "Good risk")
tbl7.5 = data.frame(Age = Age, Marital = Marital, Income=Income, Risk=Risk, stringsAsFactors = TRUE)
str(tbl7.5)
```

```{r}
d <- function(rec, df){
  d5 = c()
  for(i in 1:10){
    d2 = 0
    for(j in 1:length(rec)){
      if(class(rec[,j]) == "factor") {
        if(rec[,j] != df[i,j]) d2 = d2 + 1}
      else {dj = as.numeric(rec[j] - df[i,j]); d2 = d2 + (dj)^2}
    }
    d5 = c(d5, d2)
  }
  return(d5)
}
rec5 = tbl7.5[5,1:3]

df = cbind(tbl7.5, d(rec5, tbl7.5))
colnames(df) = c(colnames(tbl7.5), "Distance to record 5")
df[order(df[5]),]
```

```{r}
votes = 1/df[5]^2
df["Votes"] <- votes
df[order(df[5])[2:4],]
```

Votes to Good Risk are bigger than votes to Bad Loss.

but it's better to normalize =>

```{r}
tbl7.5[c(1,3)] <- lapply(tbl7.5[c(1,3)] , function(x) (x - min(x))/range(x) )
tbl7.5
```


Distances for normalized dataset

```{r}
rec5 = tbl7.5[5,1:3]

df = cbind(tbl7.5, d(rec5, tbl7.5))
colnames(df) = c(colnames(tbl7.5), "Distance to record 5")
df[order(df[5]),]
```

here are the votes for each record

```{r}
votes = 1/df[5]^2
df["Votes"] <- votes
df[order(df[5])[2:4],]
```
